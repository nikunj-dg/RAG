{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b92a2dc-672d-4dbd-99b1-7c25c0510e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9688e795-78ef-49b7-abf4-c8ab9279a0cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Installing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb67e715-d264-461d-841d-b6c968f510c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.16.23-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting databricks-langchain\n",
      "  Downloading databricks_langchain-0.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
      "  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /databricks/python3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /databricks/python3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /databricks/python3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Collecting numpy<2,>=1.26.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: chardet in /databricks/python3/lib/python3.11/site-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dataclasses-json (from unstructured)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /databricks/python3/lib/python3.11/site-packages (from unstructured) (4.10.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.30.6-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting tqdm (from unstructured)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /databricks/python3/lib/python3.11/site-packages (from unstructured) (5.9.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting onnx (from unstructured[pdf])\n",
      "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting pdf2image (from unstructured[pdf])\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pikepdf (from unstructured[pdf])\n",
      "  Downloading pikepdf-9.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting pi-heif (from unstructured[pdf])\n",
      "  Downloading pi_heif-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pypdf (from unstructured[pdf])\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting google-cloud-vision (from unstructured[pdf])\n",
      "  Downloading google_cloud_vision-3.10.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting effdet (from unstructured[pdf])\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting unstructured-inference>=0.8.7 (from unstructured[pdf])\n",
      "  Downloading unstructured_inference-0.8.7-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
      "  Downloading unstructured.pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n",
      "Collecting databricks-ai-bridge>=0.3.0 (from databricks-langchain)\n",
      "  Downloading databricks_ai_bridge-0.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting databricks-vectorsearch>=0.40 (from databricks-langchain)\n",
      "  Downloading databricks_vectorsearch-0.49-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-community>=0.2.0 (from databricks-langchain)\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting mlflow>=2.20.1 (from databricks-langchain)\n",
      "  Downloading mlflow-2.20.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting unitycatalog-langchain (from databricks-langchain)\n",
      "  Downloading unitycatalog_langchain-0.1.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: databricks-sdk>=0.34.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-ai-bridge>=0.3.0->databricks-langchain) (0.38.0)\n",
      "Collecting mlflow-skinny>=2.19.0 (from databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading mlflow_skinny-2.20.3-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: pandas in /databricks/python3/lib/python3.11/site-packages (from databricks-ai-bridge>=0.3.0->databricks-langchain) (1.5.3)\n",
      "Collecting tabulate (from databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken>=0.8.0 (from databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-vectorsearch>=0.40->databricks-langchain) (5.28.3)\n",
      "Collecting deprecation>=2 (from databricks-vectorsearch>=0.40->databricks-langchain)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.2.0->databricks-langchain)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.2.0->databricks-langchain)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.35->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Collecting Flask<4 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Jinja2<4,>=2.11 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting markdown<4,>=3.3 (from mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (3.7.2)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (14.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (1.3.0)\n",
      "Requirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=2.20.1->databricks-langchain) (1.11.1)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (3.0.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (6.0.0)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain) (0.5.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting python-multipart (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting huggingface-hub (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting onnxruntime>=1.17.0 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting torch (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting timm (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting transformers>=4.25.1 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting pypdfium2 (from unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /databricks/python3/lib/python3.11/site-packages (from pdfminer.six->unstructured[pdf]) (41.0.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /databricks/python3/lib/python3.11/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.3.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting torchvision (from effdet->unstructured[pdf])\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->unstructured[pdf])\n",
      "  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /databricks/python3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.18.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-vision->unstructured[pdf]) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-vision->unstructured[pdf]) (1.25.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib->unstructured) (1.16.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: joblib in /databricks/python3/lib/python3.11/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting Deprecated (from pikepdf->unstructured[pdf])\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting unitycatalog-ai (from unitycatalog-langchain->databricks-langchain)\n",
      "  Downloading unitycatalog_ai-0.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting nest-asyncio>=1.6.0 (from unstructured-client->unstructured)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.11/site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.15.1)\n",
      "Collecting Werkzeug>=3.1 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.2 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny>=2.19.0->databricks-ai-bridge>=0.3.0->databricks-langchain)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting blinker>=1.9 (from Flask<4->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.65.0)\n",
      "Collecting protobuf<6,>=3.12.0 (from databricks-vectorsearch>=0.40->databricks-langchain)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /databricks/python3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.68.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2<4,>=2.11->mlflow>=2.20.1->databricks-langchain)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=2.20.1->databricks-langchain) (3.0.9)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.17.0->unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas->databricks-ai-bridge>=0.3.0->databricks-langchain) (2022.7)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.2.0->databricks-langchain)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=2.20.1->databricks-langchain) (2.2.0)\n",
      "Collecting safetensors (from timm->unstructured-inference>=0.8.7->unstructured[pdf])\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from torch->unstructured-inference>=0.8.7->unstructured[pdf]) (3.13.4)\n",
      "Collecting networkx (from torch->unstructured-inference>=0.8.7->unstructu\n",
      "\n",
      "*** WARNING: max output size exceeded, skipping output. ***\n",
      "\n",
      "━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.0/207.5 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/207.5 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.6/207.5 MB\u001b[0m \u001b[31m175.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m140.8/207.5 MB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m175.6/207.5 MB\u001b[0m \u001b[31m169.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.4/207.5 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/150.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/150.1 MB\u001b[0m \u001b[31m198.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/150.1 MB\u001b[0m \u001b[31m198.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m119.3/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m149.9/150.1 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/188.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/188.7 MB\u001b[0m \u001b[31m196.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/188.7 MB\u001b[0m \u001b[31m193.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/188.7 MB\u001b[0m \u001b[31m196.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m161.5/188.7 MB\u001b[0m \u001b[31m199.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m188.5/188.7 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/21.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m141.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/253.2 MB\u001b[0m \u001b[31m220.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/253.2 MB\u001b[0m \u001b[31m190.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/253.2 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/253.2 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m202.9/253.2 MB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m243.0/253.2 MB\u001b[0m \u001b[31m197.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m253.0/253.2 MB\u001b[0m \u001b[31m199.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unitycatalog_ai-0.2.0-py3-none-any.whl (48 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unitycatalog_client-0.2.1-py3-none-any.whl (131 kB)\n",
      "Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/536.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: langdetect, antlr4-python3-runtime\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=a64942c6694647eb7a7d673ef575c6473b1367d735cbf0d20ec7a38ce242a8fd\n",
      "  Stored in directory: /home/spark-1b3eec1f-de85-433f-8587-e3/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144553 sha256=ffbd46dcf15d57bed1526cc136262c44c124663d3bd4ae04fe9eac25da389df5\n",
      "  Stored in directory: /home/spark-1b3eec1f-de85-433f-8587-e3/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built langdetect antlr4-python3-runtime\n",
      "Installing collected packages: webencodings, triton, nvidia-cusparselt-cu12, mpmath, flatbuffers, filetype, asyncio, antlr4-python3-runtime, wrapt, unstructured.pytesseract, typing-extensions, tqdm, tabulate, sympy, soupsieve, sniffio, safetensors, regex, rapidfuzz, python-multipart, python-magic, python-iso639, python-dotenv, pypdfium2, pypdf, protobuf, propcache, pi-heif, pdf2image, orjson, omegaconf, olefile, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, nest-asyncio, multidict, marshmallow, MarkupSafe, markdown, lxml, langdetect, jsonpointer, itsdangerous, humanfriendly, httpx-sse, html5lib, h11, gunicorn, greenlet, graphql-core, fsspec, frozenlist, eval-type-backport, emoji, deprecation, click, blinker, backoff, attrs, annotated-types, aiohappyeyeballs, aiofiles, yarl, Werkzeug, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, python-oxmsg, pydantic-core, opencv-python, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, Mako, jsonpatch, Jinja2, huggingface-hub, httpcore, graphql-relay, faiss-cpu, docker, Deprecated, coloredlogs, beautifulsoup4, anyio, aiosignal, tokenizers, pydantic, pikepdf, pdfminer.six, opentelemetry-api, onnxruntime, nvidia-cusolver-cu12, httpx, grpcio-status, graphene, Flask, dataclasses-json, alembic, aiohttp, unstructured-client, transformers, torch, pydantic-settings, pycocotools, opentelemetry-semantic-conventions, langsmith, aiohttp-retry, unstructured, unitycatalog-client, torchvision, opentelemetry-sdk, langchain-core, google-cloud-vision, unitycatalog-ai, timm, mlflow-skinny, langchain-text-splitters, unstructured-inference, mlflow, langchain, effdet, databricks-vectorsearch, databricks-ai-bridge, langchain-community, unitycatalog-langchain, databricks-langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.3\n",
      "    Not uninstalling protobuf at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'protobuf'. No files were found to uninstall.\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'numpy'. No files were found to uninstall.\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Not uninstalling nest-asyncio at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'nest-asyncio'. No files were found to uninstall.\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Not uninstalling click at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'click'. No files were found to uninstall.\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.4\n",
      "    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'blinker'. No files were found to uninstall.\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.6\n",
      "    Not uninstalling pydantic at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'pydantic'. No files were found to uninstall.\n",
      "  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.68.0\n",
      "    Not uninstalling grpcio-status at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'grpcio-status'. No files were found to uninstall.\n",
      "  Attempting uninstall: mlflow-skinny\n",
      "    Found existing installation: mlflow-skinny 2.11.4\n",
      "    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-1b3eec1f-de85-433f-8587-e30e40333f3c\n",
      "    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\n",
      "Successfully installed Deprecated-1.2.18 Flask-3.1.0 Jinja2-3.1.5 Mako-1.3.9 MarkupSafe-3.0.2 SQLAlchemy-2.0.38 Werkzeug-3.1.3 aiofiles-24.1.0 aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiohttp-retry-2.9.1 aiosignal-1.3.2 alembic-1.14.1 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.8.0 asyncio-3.4.3 attrs-25.1.0 backoff-2.2.1 beautifulsoup4-4.13.3 blinker-1.9.0 click-8.1.8 coloredlogs-15.0.1 databricks-ai-bridge-0.3.0 databricks-langchain-0.3.0 databricks-vectorsearch-0.49 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 effdet-0.4.1 emoji-2.14.1 eval-type-backport-0.2.2 faiss-cpu-1.10.0 filetype-1.2.0 flatbuffers-25.2.10 frozenlist-1.5.0 fsspec-2025.2.0 google-cloud-vision-3.10.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.1.1 grpcio-status-1.62.3 gunicorn-23.0.0 h11-0.14.0 html5lib-1.1 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.29.1 humanfriendly-10.0 itsdangerous-2.2.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.19 langchain-community-0.3.18 langchain-core-0.3.40 langchain-text-splitters-0.3.6 langdetect-1.0.9 langsmith-0.3.11 lxml-5.3.1 markdown-3.7 marshmallow-3.26.1 mlflow-2.20.3 mlflow-skinny-2.20.3 mpmath-1.3.0 multidict-6.1.0 nest-asyncio-1.6.0 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 olefile-0.47 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.20.1 opencv-python-4.11.0.86 opentelemetry-api-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 orjson-3.10.15 pdf2image-1.17.0 pdfminer.six-20240706 pi-heif-0.21.0 pikepdf-9.5.2 propcache-0.3.0 protobuf-4.25.6 pycocotools-2.0.8 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 pypdf-5.3.0 pypdfium2-4.30.1 python-dotenv-1.0.1 python-iso639-2025.2.18 python-magic-0.4.27 python-multipart-0.0.20 python-oxmsg-0.0.2 rapidfuzz-3.12.1 regex-2024.11.6 requests-toolbelt-1.0.0 safetensors-0.5.3 sniffio-1.3.1 soupsieve-2.6 sympy-1.13.1 tabulate-0.9.0 tiktoken-0.9.0 timm-1.0.15 tokenizers-0.21.0 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 transformers-4.49.0 triton-3.2.0 typing-extensions-4.12.2 typing-inspect-0.9.0 unitycatalog-ai-0.2.0 unitycatalog-client-0.2.1 unitycatalog-langchain-0.1.1 unstructured-0.16.23 unstructured-client-0.30.6 unstructured-inference-0.8.7 unstructured.pytesseract-0.3.13 webencodings-0.5.1 wrapt-1.17.2 yarl-1.18.3\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain unstructured \"unstructured[pdf]\" faiss-cpu databricks-langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1382875a-5fdd-4f14-8541-65df596ebec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94abccc7-544b-4a26-93bd-c5ae1cd926a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import relevant dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d61f42a-84a8-4201-9d3d-3085c6a8968c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore \n",
    "from langchain_community.vectorstores import FAISS\n",
    "from databricks_langchain import DatabricksEmbeddings\n",
    "\n",
    "import os\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63d3344c-313f-46e4-8f09-1c5a26517f68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setting up Initial Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba5189b-7775-451c-b5ca-eec7d6c65486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if 'config' not in locals(): config = {}\n",
    "\n",
    "config['DOCS_DIR'] = f\"/Volumes/practice/default/datasets/pdf\"\n",
    "config['VECTOR_STORE_PATH'] = f\"/Volumes/practice/default/rag_t2_vector_store\"\n",
    "\n",
    "embeddings = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5686a68-2e6f-4a47-9af5-0d168442bcd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG practice;\n",
    "USE SCHEMA default;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS rag_t2_files (\n",
    "  id BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "  file_name VARCHAR(128),\n",
    "  file_type VARCHAR(32),\n",
    "  file_size VARCHAR(64),\n",
    "  file_path VARCHAR(256),\n",
    "  timestamp TIMESTAMP\n",
    ") USING DELTA;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27480833-2300-4af1-a9ab-2cf844ec442b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f833dfaa-451d-4487-b7df-9fa2960a21e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0631c3d1-b85f-463e-b119-aa0e8ffec27d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def format_file_size(size_bytes):\n",
    "    units = [\"B\", \"KB\", \"MB\", \"GB\"]\n",
    "    size = float(size_bytes)\n",
    "    unit_index = 0\n",
    "\n",
    "    while size >= 1024 and unit_index < len(units) - 1:\n",
    "        size /= 1024\n",
    "        unit_index += 1\n",
    "    \n",
    "    return f\"{size:.2f} {units[unit_index]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8674293b-9282-4d08-a1c1-73985f334603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_document_details(document):\n",
    "    \"\"\"\n",
    "    Given a document, extracts details like name, type, size, path\n",
    "\n",
    "    Args:\n",
    "        document: A LangChain document object.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of details about the document\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = os.path.basename(document.metadata['source'])\n",
    "    file_type = os.path.splitext(file_name)[1][1:]\n",
    "    file_size = format_file_size(os.path.getsize(document.metadata['source']))\n",
    "\n",
    "    return [file_name, file_type, file_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "876723ec-21d4-4d82-8718-31e9f618d235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_new_docs(documents):\n",
    "    \"\"\"\n",
    "    To avoid adding duplicate documents\n",
    "   \n",
    "    Args:\n",
    "        documents: A list of new and repeat documents\n",
    "   \n",
    "    Returns:\n",
    "        list: Documents not already in db.\n",
    "    \"\"\"\n",
    "\n",
    "    new_documents = []\n",
    "\n",
    "    for document in documents:\n",
    "        details = get_document_details(document)\n",
    "        query = f\"\"\"SELECT file_name FROM rag_t2_files WHERE file_name='{details[0]}' AND file_type='{details[1]}';\"\"\"\n",
    "\n",
    "        result = spark.sql(query)\n",
    "        # print(\"Checking for duplicate result:\", result.show())\n",
    "\n",
    "        if result.isEmpty():\n",
    "            query = f\"\"\"\n",
    "            INSERT INTO rag_t2_files (file_name, file_type, file_size, file_path, timestamp) \n",
    "            VALUES ('{details[0]}', '{details[1]}', '{details[2]}', '{document.metadata['source']}', NOW());\n",
    "            \"\"\"\n",
    "            result = spark.sql(query)\n",
    "        \n",
    "        new_documents.append(document)\n",
    "\n",
    "    return new_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53d831f8-663e-4631-9422-7f6f05625c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Wrapping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5314db5a-318b-43ca-9ab9-cf02440b6ba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_docs():\n",
    "    \"\"\"\n",
    "    Reads all files in the given directory.\n",
    "   \n",
    "    Args:\n",
    "   \n",
    "    Returns:\n",
    "        list: Loaded LangChain document objects which are not present in db.\n",
    "    \"\"\"\n",
    "\n",
    "    documents = []\n",
    "    file_types=(\"*.txt\", \"*.html\", \"*.pdf\")\n",
    "\n",
    "    for file_type in file_types:\n",
    "        loader = DirectoryLoader(config['DOCS_DIR'], glob=file_type, show_progress=True)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "    documents = get_new_docs(documents)\n",
    "\n",
    "    print(f\"\\nINFO - Documents Loaded, ({len(documents)} files):\")\n",
    "    # for doc in documents:\n",
    "    #     print(f\"- {os.path.basename(doc.metadata['source'])}\", type(doc), doc)\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53870da6-2dbe-4489-addb-6b6f75cb9957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def split_docs(docs, chunk_size=1000, chunk_overlap=300, add_start_index=True):\n",
    "    \"\"\"\n",
    "    Splits text from documents into chunks and allows some overlap for continuity between chunks.\n",
    "   \n",
    "    Args:\n",
    "        documents (list): List of LangChain document objects to be split.\n",
    "        chunk_size (int): The maximum size (in characters) of each chunk (default: 1000).\n",
    "        chunk_overlap (int): The number of overlapping characters between chunks (default: 20).\n",
    "        add_start_index(bool): This tracks the starting index of each chunk within the original document, can be useful for reconstructing or referencing chunks later.\n",
    "   \n",
    "    Returns:\n",
    "        list: A list of LangChain document chunks after splitting.\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        raise ValueError(\"The input documents list is empty.\")\n",
    "   \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        add_start_index=add_start_index,\n",
    "    )\n",
    "\n",
    "    docs_chunks = text_splitter.split_documents(docs)\n",
    "    # print(f\"\\nINFO - Documents loaded: {len(documents)}, Total Splits: {len(docs_chunks)}\")\n",
    "\n",
    "    return docs_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de72fee-399e-4c79-a4c2-3980bc195ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_vector_store():\n",
    "    \"\"\"\n",
    "    Loads vector store if present or else creates one.\n",
    "\n",
    "    Args:\n",
    "   \n",
    "    Returns:\n",
    "        A vector_store.\n",
    "    \"\"\"\n",
    "    if os.path.exists(f\"{config['VECTOR_STORE_PATH']}/index.faiss\"):\n",
    "        try:\n",
    "            vector_store = FAISS.load_local(\n",
    "                folder_path=config['VECTOR_STORE_PATH'],\n",
    "                embeddings=embeddings,\n",
    "                allow_dangerous_deserialization=True  # Fix for pickle loading\n",
    "            )\n",
    "\n",
    "            print(\"Loaded vector_store\")\n",
    "\n",
    "            return vector_store\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector_store: {e}\")\n",
    "        \n",
    "            return None\n",
    "    else:\n",
    "        index = faiss.IndexFlatL2(len(embeddings.embed_query(\"Hello World !\")))\n",
    "        vector_store = FAISS(\n",
    "            embedding_function = embeddings,\n",
    "            index = index,\n",
    "            docstore = InMemoryDocstore(),\n",
    "            index_to_docstore_id = {},\n",
    "        )\n",
    "\n",
    "        print(\"Created a new vector_store\")\n",
    "\n",
    "        return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6456edaf-32e2-4662-aa1a-4e3e13809bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def embed_store(docs_chunks, vector_store):\n",
    "    \"\"\"\n",
    "    Embeds the document chunks and store them\n",
    "\n",
    "    Args:\n",
    "        docs_chunks (list): List of LangChain document chunks to be embedded.\n",
    "        vector_store (vector_store): The vector store object containing embedded chunks.\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    vector_store.add_documents(docs_chunks)\n",
    "\n",
    "    vector_store.save_local(config['VECTOR_STORE_PATH'])\n",
    "\n",
    "    print(\"\\n INFO - vector_store saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dec16d3-3f5d-49fb-b631-5874e1ac0707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9213441d-da71-4b5a-ac24-92210905dec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: Loading the documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
      "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
      "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\r100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|num_affected_rows|num_inserted_rows|\n",
      "+-----------------+-----------------+\n",
      "|                1|                1|\n",
      "+-----------------+-----------------+\n",
      "\n",
      "Inserting value result: None\n",
      "No duplicates\n",
      "\n",
      "INFO - Documents Loaded, (1 files):\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep: Loading the documents\")\n",
    "documents = load_docs() ## loads docs from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e9c15ef-8391-4d6c-975b-95e3280b9087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step: Chunking the documents\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    print(\"\\nStep: Chunking the documents\")\n",
    "    docs_chunks = split_docs(documents, chunk_overlap=100) ## split docs in chunks\n",
    "else:\n",
    "    print(\"\\nNo new files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e4f377b-b732-4dd1-9c3d-07a814a38422",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Loading the vector store\n",
      "Created a new vector_store\n"
     ]
    }
   ],
   "source": [
    "print(\"Step: Loading the vector store\")\n",
    "vector_store = load_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af4365f-3276-41d1-8c12-b53991245334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " INFO - vector_store saved\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    embed_store(docs_chunks, vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82fd2a88-617f-4875-aac7-325bd05a8223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Scratch Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d897edac-a64b-490a-8905-3d200c903974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>file_name</th><th>file_type</th><th>file_size</th><th>file_path</th><th>timestamp</th></tr></thead><tbody><tr><td>1</td><td>electric_vehicles.pdf</td><td>pdf</td><td>96.72 KB</td><td>/Volumes/practice/default/datasets/pdf/electric_vehicles.pdf</td><td>2025-02-28T18:37:06.452Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "electric_vehicles.pdf",
         "pdf",
         "96.72 KB",
         "/Volumes/practice/default/datasets/pdf/electric_vehicles.pdf",
         "2025-02-28T18:37:06.452Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "id",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(128)"
            },
            "name": "file_name",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(32)"
            },
            "name": "file_type",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(64)"
            },
            "name": "file_size",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {
             "__CHAR_VARCHAR_TYPE_STRING": "varchar(256)"
            },
            "name": "file_path",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "timestamp",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 42
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(128)\"}",
         "name": "file_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(32)\"}",
         "name": "file_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(64)\"}",
         "name": "file_size",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__CHAR_VARCHAR_TYPE_STRING\": \"varchar(256)\"}",
         "name": "file_path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM rag_t2_files;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6334038739617037,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
